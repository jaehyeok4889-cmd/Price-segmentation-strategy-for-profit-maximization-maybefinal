# %% 1. Imports & 기본 설정

import numpy as np
import pandas as pd
from pathlib import Path
import os
import time

# 파일 업로드 함수 제거 (로컬 파일 시스템 사용)
# from google.colab import files # 제거

import matplotlib.pyplot as plt

# Matplotlib 백엔드 설정 (GitHub Actions 또는 서버 환경에서 필요할 수 있음)
# plt.switch_backend('Agg') 

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    roc_auc_score, accuracy_score, precision_recall_fscore_support,
    mean_absolute_error, mean_squared_error
)
from sklearn.isotonic import IsotonicRegression

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from tqdm.auto import tqdm

# 재현성
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# 가격 & 피처 설정
BASE_PRICE = 9000.0
Feat_Col = ["multi_purchase_count", "total_purchase_last_month", "cart_abandon_count"]

# DNN 하이퍼파라미터
EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 1e-3
VAL_SPLIT = 0.2
TEST_SIZE = 0.20

# %% 2. 데이터 로드 및 기본 전처리 (수정된 부분)

# 데이터 파일 경로 설정 (GitHub 저장소에 'input_data.xlsx'가 있다고 가정)
# 사용자에게 파일 이름을 명확히 전달하기 위해 변경
data_file_name = "input_data.xlsx"
print(f"Loading data from: {data_file_name}")

try:
    # 엑셀 읽기
    df = pd.read_excel(data_file_name, sheet_name="Sheet1")
except FileNotFoundError:
    print(f"Error: The file '{data_file_name}' was not found.")
    print("Please ensure 'input_data.xlsx' is in the same directory.")
    exit()

df = df.reset_index(drop=True)
df["customer_id"] = df.index.astype(int)

print("Loaded shape:", df.shape)
print("Columns:", df.columns.tolist())

# 가격 조정용 분포 (0 제외)
multi_vals = df.loc[df["multi_purchase_count"] > 0, "multi_purchase_count"]
total_vals = df.loc[df["total_purchase_last_month"] > 0, "total_purchase_last_month"]
abandon_vals = df.loc[df["cart_abandon_count"] > 0, "cart_abandon_count"]


def scale_adjust(value, series, min_adj=-500, max_adj=500):
    """분위수 기반 선형 보정"""
    rank = (series <= value).mean()
    return min_adj + (max_adj - min_adj) * rank


def abandon_adjust(value, series, min_adj=-500, max_adj=-100):
    """망설임(카트 이탈) 보정: 값이 클수록 더 큰 할인(더 음수 쪽)"""
    rank = (series <= value).mean()
    return min_adj + (max_adj - min_adj) * rank


# 소비자별 맞춤 가격 계산
adjusted_prices = []

for _, row in df.iterrows():
    multi_val = row["multi_purchase_count"]
    total_val = row["total_purchase_last_month"]
    abandon_val = row["cart_abandon_count"]

    multi_adj = scale_adjust(multi_val, multi_vals)
    total_adj = scale_adjust(total_val, total_vals)

    if abandon_val > 0:
        abandon_adj_val = abandon_adjust(abandon_val, abandon_vals)
    else:
        abandon_adj_val = 0.0

    final_price = BASE_PRICE + multi_adj + total_adj + abandon_adj_val

    # 완전 신규(모든 값 0)이면 기본가
    if multi_val == 0 and total_val == 0 and abandon_val == 0:
        final_price = BASE_PRICE

    adjusted_prices.append(round(final_price, -2))  # 100원 단위 반올림

df["adjusted_price"] = adjusted_prices

# %% 3. Synthetic label & offered_price 생성 (생략 없음)

rng = np.random.default_rng(RANDOM_SEED)

lp_multi = np.log1p(df["multi_purchase_count"].astype(float).values)
lp_total = np.log1p(df["total_purchase_last_month"].astype(float).values)
lp_abnd  = np.log1p(df["cart_abandon_count"].astype(float).values)

# 과거 히스토리 기반 가격 (대략적 변동)
sens = 1.0 + 0.15 * (lp_abnd - lp_abnd.mean())  # 망설임이 많을수록 살짝 감도 조정
hist_noise = rng.normal(loc=0.0, scale=400.0, size=len(df))

offered_price = (BASE_PRICE * sens + hist_noise).clip(BASE_PRICE * 0.6, BASE_PRICE * 1.5)
df["synthetic_historical_price"] = offered_price

# 잠재 로짓 모델 → 구매 확률
w0 = -0.2
w_total = 0.9
w_multi = 0.8
w_abnd  = 1.0
w_price = 2.0

x_price = (offered_price - BASE_PRICE) / BASE_PRICE
latent = w0 + w_total * lp_total + w_multi * lp_multi - w_abnd * lp_abnd - w_price * x_price
prob   = 1 / (1 + np.exp(-latent))

y = rng.binomial(n=1, p=prob, size=len(df))

df["synthetic_conversion_prob"] = prob
print("Positive rate (mean of y):", np.mean(y).round(4))

# %% 4. 피처 구성 & 스케일링 (생략 없음)

X_feats = df[Feat_Col].astype(float).copy()
X_feats["offered_price"] = offered_price

# count 계열은 log1p
for col in Feat_Col:
    X_feats[col] = np.log1p(X_feats[col])

scaler = StandardScaler()
X = scaler.fit_transform(X_feats.values)

feature_names = list(X_feats.columns)
print("Feature order:", feature_names)

# %% 5. DNN 모델 정의 (생략 없음)

def build_model(input_dim: int) -> keras.Model:
    inp = keras.Input(shape=(input_dim,), name="features")
    x = inp
    for units in [32, 16]:
        x = layers.Dense(units, activation="relu")(x)
        x = layers.Dropout(0.1)(x)
    out = layers.Dense(1, activation="sigmoid", name="purchase_prob")(x)

    model = keras.Model(inputs=inp, outputs=out)
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss="binary_crossentropy",
        metrics=["accuracy", keras.metrics.AUC(name="auc")],
    )
    return model

# %% 6. Train / Val / Test split + 학습 & 검증 (생략 없음)

all_idx = np.arange(X.shape[0])

# 1) test 20% 홀드아웃
X_trainval, X_test, y_trainval, y_test, idx_trainval, idx_test = train_test_split(
    X, y, all_idx,
    test_size=TEST_SIZE,
    random_state=RANDOM_SEED,
    stratify=y
)

# 2) train / val 분리
X_train, X_val, y_train, y_val, idx_train, idx_val = train_test_split(
    X_trainval, y_trainval, idx_trainval,
    test_size=VAL_SPLIT,
    random_state=RANDOM_SEED,
    stratify=y_trainval
)

print(">> Shapes")
print(f"  train: {X_train.shape}  val: {X_val.shape}  test: {X_test.shape}")

# 모델 학습
model = build_model(X.shape[1])

callbacks = [
    keras.callbacks.EarlyStopping(
        patience=10, restore_best_weights=True,
        monitor="val_auc", mode="max"
    )
]

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks,
    verbose=0
)

# Validation metrics
val_prob = model.predict(X_val, verbose=0).ravel()
val_pred = (val_prob >= 0.5).astype(int)

val_auc = roc_auc_score(y_val, val_prob)
val_acc = accuracy_score(y_val, val_pred)
val_prec, val_rec, val_f1, _ = precision_recall_fscore_support(
    y_val, val_pred, average="binary", zero_division=0
)

print("\n== Validation metrics ==")
print(f"AUC:  {val_auc:.4f}  ACC: {val_acc:.4f}  PREC: {val_prec:.4f}  REC: {val_rec:.4f}  F1: {val_f1:.4f}")

# Test metrics (prob vs label)
test_prob = model.predict(X_test, verbose=0).ravel()
test_pred = (test_prob >= 0.5).astype(int)

test_auc = roc_auc_score(y_test, test_prob)
test_acc = accuracy_score(y_test, test_pred)
test_prec, test_rec, test_f1, _ = precision_recall_fscore_support(
    y_test, test_pred, average="binary", zero_division=0
)

mse   = mean_squared_error(y_test, test_prob)
rmse  = float(np.sqrt(mse))
mae   = mean_absolute_error(y_test, test_prob)
brier = mse  # Brier score = MSE(prob, label)

print("\n== Test metrics ==")
print(f"AUC:  {test_auc:.4f}  ACC: {test_acc:.4f}  PREC: {test_prec:.4f}  REC: {test_rec:.4f}  F1: {test_f1:.4f}")
print(f"MAE(prob vs label):  {mae:.4f}")
print(f"RMSE(prob vs label): {rmse:.4f}")
print(f"Brier score:         {brier:.4f}")

# %% 7. 헬퍼 함수 + 아티팩트 저장 (수정된 부분)

def get_price(customer_id: int) -> float:
    """맞춤 가격(adjusted_price) 조회"""
    return float(
        df.loc[df["customer_id"] == customer_id, "adjusted_price"].iloc[0]
    )


# ... (get_info1, get_info2, get_info3 함수 생략 - 변화 없음) ...

def predict_probability(customer_id: int, offered_price_input: float) -> float:
    """
    customer_id의 피처 + 주어진 가격으로 구매확률 예측.
    """
    row = df.loc[df["customer_id"] == customer_id].iloc[0]
    feats = [np.log1p(float(row[c])) for c in Feat_Col]
    feats.append(float(offered_price_input))
    feats_scaled = scaler.transform([feats])
    prob = float(model.predict(feats_scaled, verbose=0).ravel()[0])
    return prob


def inspect_customer(customer_id: int):
    """한 명 고객 기록 + 해당 고객 맞춤가에서의 구매확률 출력"""
    price = get_price(customer_id)
    rec = df.loc[df["customer_id"] == customer_id,
                 ["customer_id"] + Feat_Col + ["adjusted_price"]]
    print("<Customer Record>")
    print(rec.to_string(index=False))
    p = predict_probability(customer_id, price)
    print(f"\nPredicted purchase probability at price {int(price)}: {p:.3%}")


# 모델/스케일러/피처 이름 저장
out_dir = Path(".")
# out_dir이 존재하는지 확인 (GitHub Actions에서 필요할 수 있음)
if not out_dir.exists():
    out_dir.mkdir(parents=True, exist_ok=True)

model_path = out_dir / "price_propensity_model.h5"
scaler_path = out_dir / "feature_scaler.npy"
cols_path = out_dir / "feature_names.txt"

model.save(model_path)
np.save(
    scaler_path,
    {"mean_": scaler.mean_, "scale_": scaler.scale_, "feature_names": feature_names},
    allow_pickle=True
)
with open(cols_path, "w") as f:
    f.write("\n".join(feature_names))

print("Saved:")
print(" -", model_path.resolve())
print(" -", scaler_path.resolve())
print(" -", cols_path.resolve())

# %% 8. Price-Demand Curve Panel & Summary CSV 생성 (생략 없음)

BUY_THRESHOLD = 0.75
LOW_RATIO, HIGH_RATIO, STEP_WON = 0.6, 1.5, 100

customer_ids = df["customer_id"].astype(int).tolist()

grid = np.arange(
    max(0, BASE_PRICE * LOW_RATIO),
    BASE_PRICE * HIGH_RATIO + STEP_WON,
    STEP_WON,
    dtype=float
)
G = len(grid)

# 피처 캐시 (log1p 적용된 3개 피처)
_fixed = np.zeros((len(customer_ids), len(Feat_Col)), dtype=float)
for j, cid in enumerate(tqdm(customer_ids, desc="Caching features", dynamic_ncols=True, mininterval=0.1)):
    r = df.loc[df["customer_id"] == cid].iloc[0]
    _fixed[j, :] = np.log1p(r[Feat_Col].astype(float).values)


def batch_predict_one_customer(fixed_feats_row: np.ndarray, prices: np.ndarray) -> np.ndarray:
    X = np.column_stack([
        np.repeat(fixed_feats_row.reshape(1, -1), len(prices), axis=0),
        prices.astype(float).reshape(-1, 1)
    ])
    Xs = scaler.transform(X)
    return model.predict(Xs, verbose=0).ravel()


def elasticity_np(price: np.ndarray, q: np.ndarray, eps: float = 1e-9) -> np.ndarray:
    dQ = np.gradient(q)
    dP = np.gradient(price)
    P = np.maximum(eps, price)
    Q = np.maximum(eps, q)
    return (dQ / np.maximum(eps, dP)) * (P / Q)


rows = []
summary_rows = []

t0 = time.time()

for idx, cid in enumerate(tqdm(customer_ids, desc="Building panel (fast)", dynamic_ncols=True, mininterval=0.1)):
    probs = batch_predict_one_customer(_fixed[idx], grid)
    decision = (probs >= BUY_THRESHOLD).astype(int)
    rev_prob = grid * probs
    rev_rule = grid * decision
    elast    = elasticity_np(grid, probs)

    # 세부 패널
    for i in range(G):
        rows.append({
            "customer_id": cid,
            "price": float(grid[i]),
            "prob": float(probs[i]),
            "buy_rule_075": int(decision[i]),
            "revenue_prob": float(rev_prob[i]),
            "revenue_rule": float(rev_rule[i]),
            "elasticity_prob": float(elast[i]),
        })

    # 요약
    i_prob_opt = int(np.argmax(rev_prob))
    i_rule_opt = int(np.argmax(rev_rule))
    zone_mask  = decision == 1

    if np.any(zone_mask):
        i_zone_opt_local = int(np.argmax(rev_prob[zone_mask]))
        zone_indices = np.nonzero(zone_mask)[0]
        zi = int(zone_indices[i_zone_opt_local])
        zone_price, zone_prob = float(grid[zi]), float(probs[zi])
        zone_rev, zone_E      = float(rev_prob[zi]), float(elast[zi])
    else:
        zone_price = zone_prob = zone_rev = zone_E = np.nan

    base_idx = int(np.argmin(np.abs(grid - BASE_PRICE)))

    summary_rows.append({
        "customer_id": int(cid),
        "opt_prob_price": float(grid[i_prob_opt]),
        "opt_prob_prob":  float(probs[i_prob_opt]),
        "opt_prob_revenue": float(rev_prob[i_prob_opt]),
        "opt_prob_elasticity": float(elast[i_prob_opt]),
        "opt_rule_price": float(grid[i_rule_opt]),
        "opt_rule_decision": int(decision[i_rule_opt]),
        "opt_rule_revenue": float(rev_rule[i_rule_opt]),
        "opt_in_rule_price": zone_price,
        "opt_in_rule_prob":  zone_prob,
        "opt_in_rule_revenue": zone_rev,
        "opt_in_rule_elasticity": zone_E,
        "base_price": float(grid[base_idx]),
        "base_prob":  float(probs[base_idx]),
        "base_buy_rule_075": int(decision[base_idx]),
        "base_elasticity_prob": float(elast[base_idx]),
    })

panel = pd.DataFrame(rows)
summary_df = pd.DataFrame(summary_rows)

panel.to_csv("all_customers_curve.csv", index=False)
summary_df.to_csv("all_customers_summary.csv", index=False)

print("✓ Saved: all_customers_curve.csv")
print("✓ Saved: all_customers_summary.csv")
print(f"Rows(panel)={len(panel):,}  Customers={len(customer_ids):,}  Grid={G:,}")
print(f"Elapsed: {time.time()-t0:.1f} sec")

# %% 9. per-customer summary 엑셀 + 탄력성 차트 (수정된 부분)

# 제공 가격은 adjusted_price 기준
provided_price_col = "adjusted_price"

def point_elasticity(customer_id: int, price: float, h: float = 100.0) -> float:
    p0, p1 = price - h, price + h
    q0 = float(predict_probability(customer_id, p0))
    q  = float(predict_probability(customer_id, price))
    q1 = float(predict_probability(customer_id, p1))
    dQ_dP = (q1 - q0) / max(1e-9, (p1 - p0))
    if q <= 1e-9:
        return 0.0
    return dQ_dP * (price / q)


BUY_THRESHOLD = 0.75
rows = []

for r in tqdm(df.itertuples(index=False), total=len(df), desc="build summary", dynamic_ncols=True, mininterval=0.1):
    cid = int(getattr(r, "customer_id"))
    price = float(getattr(r, provided_price_col))
    prob  = float(predict_probability(cid, price))
    decision = int(prob >= BUY_THRESHOLD)
    elast = float(point_elasticity(cid, price, h=100.0))

    rows.append({
        "customer_id": cid,
        "multi_purchase_count": int(getattr(r, "multi_purchase_count")),
        "total_purchase_last_month": int(getattr(r, "total_purchase_last_month")),
        "cart_abandon_count": int(getattr(r, "cart_abandon_count")),
        "provided_price": int(round(price)),
        "purchase_probability": round(prob, 4),
        "will_buy_075": decision,
        "elasticity": round(elast, 4),
        "expected_revenue_prob": round(price * prob, 2),
    })

summary = pd.DataFrame(rows)

out_path = "customer_price_elasticity_report.xlsx"
# openpyxl 엔진은 기본적으로 설치되어 있어야 함
try:
    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        cols = [
            "customer_id",
            "multi_purchase_count",
            "total_purchase_last_month",
            "cart_abandon_count",
            "provided_price",
            "purchase_probability",
            "will_buy_075",
            "elasticity",
            "expected_revenue_prob",
        ]
        summary[cols].to_excel(writer, index=False, sheet_name="summary")
    print(f"Saved: {out_path}")
except ImportError:
    print("Warning: openpyxl not installed. Saving summary as CSV instead.")
    summary.to_csv("customer_price_elasticity_report.csv", index=False)
    print("Saved: customer_price_elasticity_report.csv")


# 차트 저장 (plt.show() 대신 savefig 사용)
# Colab 환경이 아니므로, plt.show() 대신 저장하여 웹사이트에 활용합니다.
def save_chart(fig_name: str, title: str, xlabel: str, ylabel: str, data, plot_type='hist'):
    plt.figure()
    if plot_type == 'hist':
        plt.hist(data, bins=30)
    elif plot_type == 'scatter':
        plt.scatter(data[0], data[1], s=12)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(fig_name)
    plt.close() # 메모리 해제

elvals = summary["elasticity"].replace([np.inf, -np.inf], np.nan).dropna().values
if len(elvals) > 0:
    save_chart("chart_elasticity_distribution.png", "Elasticity distribution (at provided price)", "Elasticity (E)", "Count", elvals)

save_chart("chart_price_vs_prob.png", "Provided price vs. purchase probability", "Provided price", "Purchase probability", 
           [summary["provided_price"].values, summary["purchase_probability"].values], plot_type='scatter')

save_chart("chart_price_vs_elasticity.png", "Provided price vs. elasticity", "Provided price", "Elasticity (E)", 
           [summary["provided_price"].values, summary["elasticity"].values], plot_type='scatter')


# %% 10. Aggregate elasticity curve + CSV (수정된 부분)

# ... (batch_predict_one_customer_agg 정의는 생략 - 변화 없음) ...
def batch_predict_one_customer_agg(row, prices):
    fx = [np.log1p(float(row[c])) for c in Feat_Col]
    X = np.column_stack([
        np.repeat(np.array(fx)[None, :], len(prices), axis=0),
        prices.astype(float).reshape(-1, 1)
    ])
    Xs = scaler.transform(X)
    return model.predict(Xs, verbose=0).ravel()

sum_probs = np.zeros(G, dtype=float)
sum_rev   = np.zeros(G, dtype=float)

for cid in tqdm(customer_ids, total=len(customer_ids), desc="Aggregate probs", dynamic_ncols=True, mininterval=0.1):
    r = df.loc[df["customer_id"] == cid].iloc[0]
    probs = batch_predict_one_customer_agg(r, grid)
    sum_probs += probs
    sum_rev   += grid * probs

N = len(customer_ids)
Q_mean = sum_probs / max(1, N)
Q_tot  = sum_probs
Rev_tot = sum_rev

# 탄력성
dQ = np.gradient(Q_mean)
dP = np.gradient(grid)
P  = np.maximum(1e-9, grid)
Q  = np.maximum(1e-9, Q_mean)
E  = (dQ / np.maximum(1e-9, dP)) * (P / Q)

agg_curve = pd.DataFrame({
    "price": grid,
    "Q_mean": Q_mean,
    "Q_total": Q_tot,
    "elasticity_meanQ": E,
    "revenue_total": Rev_tot
})

# 플롯 저장
save_chart("chart_agg_demand.png", "Aggregate demand (mean probability across customers)", "Price", "Q_mean", 
           [agg_curve["price"].values, agg_curve["Q_mean"].values], plot_type='scatter')
save_chart("chart_agg_elasticity.png", "Aggregate price elasticity (based on mean Q)", "Price", "Elasticity (E)", 
           [agg_curve["price"].values, agg_curve["elasticity_meanQ"].values], plot_type='scatter')
save_chart("chart_agg_revenue.png", "Total expected revenue across customers", "Price", "Revenue (total)", 
           [agg_curve["price"].values, agg_curve["revenue_total"].values], plot_type='scatter')


agg_curve.to_csv("aggregate_elasticity_curve.csv", index=False)
print("Saved: aggregate_elasticity_curve.csv")

# %% 11. Conservative pricing + 3-tier 메뉴 (보정된 가격 정책) - 결과 출력 수정

unit_cost           = 6000.0
PRICE_MIN_FACTOR    = 0.60
PRICE_MAX_FACTOR    = 1.05
GRID_STEP           = 100.0
MIN_PROB            = 0.02
PROB_CAP            = 0.85
SHRINK_LAM          = 0.35
LCB_Z               = 1.64
SLOPE_ALPHA         = 2.0
MENU_K              = 3
TOP_K_SHOW          = 5
PRED_BATCH          = 16384

# grid
low  = max(0.0, BASE_PRICE * PRICE_MIN_FACTOR)
high = BASE_PRICE * PRICE_MAX_FACTOR
grid_clip = np.arange(low, high + GRID_STEP, GRID_STEP, dtype=float)
grid_clip = np.asarray(sorted(np.unique(grid_clip)))
G = grid_clip.size

# Isotonic calibration (val 세트 기준)
val_raw = model.predict(X_val, verbose=0).ravel()
iso = IsotonicRegression(out_of_bounds="clip").fit(val_raw, y_val)

# 피처 캐시
N = len(df)
F = np.column_stack([
    np.log1p(df[Feat_Col[0]].astype(float).values),
    np.log1p(df[Feat_Col[1]].astype(float).values),
    np.log1p(df[Feat_Col[2]].astype(float).values),
]).astype(float)


def predict_prob_matrix(F, grid_clip, batch=PRED_BATCH):
    N, d = F.shape
    G = grid_clip.size
    Pcol = np.repeat(grid_clip.reshape(1, G), N, axis=0).reshape(-1, 1)
    Fbig = np.repeat(F, G, axis=0)
    Xbig = np.concatenate([Fbig, Pcol], axis=1)
    Xs   = scaler.transform(Xbig)

    raw = np.empty(Xs.shape[0], dtype=float)
    for s in tqdm(range(0, Xs.shape[0], batch),
                  desc="Predict (batched)", dynamic_ncols=True, mininterval=0.1):
        e = min(s + batch, Xs.shape[0])
        raw[s:e] = model.predict(Xs[s:e], verbose=0).ravel()

    prob = iso.predict(raw)
    p_ref = float(np.mean(y_val))
    prob = (1 - SHRINK_LAM) * prob + SHRINK_LAM * p_ref
    prob = np.clip(prob, 1e-6, PROB_CAP)
    return prob.reshape(N, G)


P_raw = predict_prob_matrix(F, grid_clip)  # (N,G)

def _logit(p):
    p = np.clip(p, 1e-6, 1-1e-6)
    return np.log(p / (1 - p))

def _sigm(z):
    return 1 / (1 + np.exp(-z))

# price tilt
price_tilt = (grid_clip - BASE_PRICE) / max(1e-9, BASE_PRICE)
Z = _logit(P_raw) - SLOPE_ALPHA * price_tilt.reshape(1, -1)
P_raw = np.clip(_sigm(Z), 1e-6, PROB_CAP)

# price에 따른 단조 감소 enforcing
order = np.argsort(grid_clip)
inv   = np.argsort(order)
P_sorted = P_raw[:, order]
P_sorted = np.minimum.accumulate(P_sorted, axis=1)
P = np.clip(P_sorted[:, inv], MIN_PROB, PROB_CAP)

# Lower-confidence profit
Var   = np.maximum(P * (1 - P), 1e-9)
P_lcb = np.clip(P - LCB_Z * np.sqrt(Var), 1e-6, PROB_CAP)
Profit = (grid_clip.reshape(1, -1) - unit_cost) * P_lcb  # (N,G)

# 고객별 best price
best_idx    = np.argmax(Profit, axis=1)
best_price  = grid_clip[best_idx]
best_prob   = P[np.arange(N), best_idx]
best_profit = Profit[np.arange(N), best_idx]
order_top   = np.argsort(-best_profit)

print("\n== 3. 3-tier MENU & Profit Analysis ==")
print("Personalized (top K) - Best Profit Price:")
for i in order_top[:TOP_K_SHOW]:
    cid = int(df.iloc[i]["customer_id"])
    print(f"cid={cid:>4}  price={int(best_price[i]):>5}  prob={best_prob[i]:.3f}  exp_profit={best_profit[i]:.1f}")

# Elasticity (중앙 차분, P_raw 기준)
base_idx = int(np.argmin(np.abs(grid_clip - BASE_PRICE)))
base_idx = int(np.clip(base_idx, 1, G-2))
im1, ip1 = base_idx - 1, base_idx + 1
dQ = P_raw[:, ip1] - P_raw[:, im1]
dP = (grid_clip[ip1] - grid_clip[im1]) + 1e-9
Qb = np.maximum(P_raw[:, base_idx], 1e-9)
Pb = grid_clip[base_idx]
elas = (dQ / dP) * (Pb / Qb)

# 절대 탄력성 기준 tertile segment
absE = np.abs(elas)
rank = absE.argsort().argsort()
segments = np.zeros(N, dtype=int)

cut1 = N // 3
cut2 = 2 * N // 3
segments[(rank >= cut1) & (rank < cut2)] = 1
segments[rank >= cut2] = 2

# 빈 세그먼트 방지 로직 (원래 코드 유지)
for s in (0, 1, 2):
    if np.sum(segments == s) == 0:
        k = np.argmin(np.abs(rank - (cut1 if s == 0 else (cut2 if s == 2 else (cut1+cut2)//2))))
        segments[k] = s

# 3-tier 메뉴 가격
print("\n3-tier MENU (balanced tertiles) Optimal Price:")
menu_prices = {}
menu_results = []
for seg in range(MENU_K):
    idx = np.where(segments == seg)[0]
    seg_profit_mean = Profit[idx].mean(axis=0)
    j = int(np.argmax(seg_profit_mean))
    mp = int(grid_clip[j])
    mp_prob = float(P[idx, j].mean())
    mp_profit = float(seg_profit_mean[j])
    menu_prices[seg] = mp
    print(f"SEG{seg}  n={idx.size:4}  price={mp:5}  mean_prob={mp_prob:.3f}  mean_profit={mp_profit:.2f}")
    menu_results.append({
        "segment": seg,
        "n_customers": idx.size,
        "menu_price": mp,
        "mean_prob": mp_prob,
        "mean_profit": mp_profit
    })

menu_df = pd.DataFrame(menu_results)
menu_df.to_csv("3_tier_menu_results.csv", index=False)
print("Saved: 3_tier_menu_results.csv")


# BASE vs 메뉴 uplift
base_idx = int(np.argmin(np.abs(grid_clip - BASE_PRICE)))
base_mean = float(Profit[:, base_idx].mean())
menu_vec = np.zeros(N, dtype=float)

for seg in range(MENU_K):
    idx = np.where(segments == seg)[0]
    j = int(np.where(grid_clip == menu_prices[seg])[0][0])
    menu_vec[idx] = Profit[idx, j]

menu_mean = float(menu_vec.mean())
uplift = (menu_mean - base_mean) / max(1e-9, base_mean)

print(f"\nTotal expected profit uplift vs BASE({int(BASE_PRICE)}): {uplift*100:.2f}%")

# Diagnostics (GitHub Actions 로그를 위해 출력 유지)
cap = grid_clip.max()
cap_hit_all = float(np.mean(best_price == cap))

print("\n== Diagnostics ==")
print(f"P (final)   : mean={P.mean():.3f},   min={P.min():.3f},   max={P.max():.3f}")
q1 = np.quantile(np.abs(elas), 1/3)
q2 = np.quantile(np.abs(elas), 2/3)
print(f"|E| quantile: 33%={q1:.4f}, 67%={q2:.4f}")
print(f"Cap-hit ratio (all): {cap_hit_all*100:.2f}%  (cap={int(cap)})")
# ... (Segment별 Cap-hit ratio 출력 생략 - 로그 비중이 크므로)
